---
title: "Which Data Tells the Truth? A Multi-modal Deep Learning Framework for Stock Price Movement Prediction"
collection: publications
category: books
permalink: /publication/paper3
excerpt: 'Submitted'
# date: 2009-10-01
# venue: 'Journal 1'
# slidesurl: 'https://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://academicpages.github.io/files/paper3.pdf'
# bibtexurl: 'https://academicpages.github.io/files/bibtex1.bib'
# citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
Abstract: This paper introduces a novel multimodal data framework for stock price movement prediction, combining stock graphical, market, and text modalities with state-of-the-art natural language processing models such as BERT. Our model addresses two key challenges in return prediction about how to extract signals from different types of data and which type of data dominates others. Using a 20-year US stock market dataset, we show that deep learning and language models efficiently capture critical features, with time series data proving more influential than graphical and text modalities. The framework's attention mechanisms and weight allocation effectively reduce conflicts between modalities. Our best-performing model, Fusion(AW), achieves a higher balanced accuracy and a Sharpe ratio of 3.05 annually, outperforming single- and dual-modal approaches. Moreover, our model shows its ability and robustness in three recent periods—the COVID-19 crash (2020), the Russia–Ukraine shock (2022–2023), and the AI-driven expansion (2023–present). This research has broad implications for investment decision-making and paves the way for further exploration of multimodal data in financial modeling.